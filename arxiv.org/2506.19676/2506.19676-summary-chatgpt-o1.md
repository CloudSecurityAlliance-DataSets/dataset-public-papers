**Summary of “A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures”**

- **Context & Motivation**  
  • LLM-driven AI agents increasingly collaborate with external tools, users, and other agents, forming an “Internet of Agents” (IoA).  
  • This paper provides a comprehensive analysis of how these communication protocols operate, their security threats, and potential defense mechanisms.  
  • Agent communication is categorized into three phases: User-Agent, Agent-Agent, and Agent-Environment. Each phase introduces distinct vulnerabilities and requires targeted mitigations.

---

### 1. User-Agent Interaction
- **Protocols**  
  • PXP [256]: Allows structured two-way “explanation” messages between users and agents in data-intensive tasks (e.g., radiology).  
  • Spatial Population Protocols [56]: Minimalist model for distance or location-based robot interactions, supporting pairwise distance exchange.  
  • AG-UI [217]: Client-server-based event streaming mechanism, enabling user applications to communicate with agent backends via typed “event streams.”

- **Security Risks**  
  • Malicious Users → Benign Agents  
    – Text-based Attacks: Prompt injection (direct or indirect), jailbreak prompts bypassing safety layers [182], [324].  
    – Multimodal Attacks: Adversarial images or waveforms that embed malicious cues [174], [320].  
    – Privacy Leakage: Sensitive agent info (system prompts, model structure) can be extracted [282].  
    – Denial of Service: Attacks that waste agent resources (overthinking or repeated tasks) [149], [343].  
  • Compromised Agents → Benign Users  
    – Violating User Privacy: Leaks personal data, performs behavioral profiling [172].  
    – Psychological & Social Manipulation: Subtly shifts user beliefs, impersonates the user’s style [92], [220].  
    – Harmful Task Execution: Economic sabotage, malicious code generation, or providing dangerous advice [158], [183].

- **Defenses**  
  • Input/Output Filtering: Use fine-tuned safety filters or specialized classifiers [122], [166].  
  • Cross-Modal Consistency Checks: Ensure images/audios match textual prompts to block hidden instructions.  
  • Privacy Protection: Data minimization, differential privacy on biometric data, and multi-layer detection modules [166], [301].  
  • Resource Management: Quotas, anomaly detection, sensor-based triggers to mitigate DoS or “overthink” scenarios [149], [339].

---

### 2. Agent-Agent Communication
- **Protocol Taxonomy**  
  1. **CS-based**: Centralized servers manage agent IDs and capabilities (e.g., ACP-IBM [119], ACP-AGNTCY [47]).  
  2. **P2P-based**: Decentralized discovery via DHT or domain-based URIs (e.g., ACN [230], ANP [263]).  
  3. **Hybrid**: Support both centralized registries and decentralized lookups (e.g., LMOS [76], A2A [89], Agora [198]).  
  4. **Others**: Protocols focusing on communication format rather than discovery (e.g., Agent Protocol [153], AITP [9]).

- **Security Threats**  
  • CS-specific  
    – Registration Pollution: Attackers create many fake agents to overwhelm listings or mimic legitimate ones [265].  
    – Description Poisoning: Tampering with agent capability descriptors to misroute tasks [207].  
    – Task Flooding: Exhaust server resources with expensive queries.  
  • P2P-specific  
    – Non-convergence: Complex tasks loop endlessly in multi-agent collaborations [218].  
    – MITM: Attackers intercept or forge agent messages [106].  
  • Universal  
    – Agent Spoofing / Exploitation: Compromised agents can spread malicious commands [133], [158].  
    – Privacy Leakage: Unauthorized data sharing among agents, complex cross-agent infiltration [140].  
    – Responsibility Evasion: Hard to pinpoint blame when multi-step collaborations fail [218].  
    – Denial of Service: Recursive blocking attacks across the network [362].

- **Defense Approaches**  
  • CS-based: Strict registration verification, capability testing, load balancing, anti-SEO manipulation.  
  • P2P-based: Task lifecycle monitoring, robust end-to-end encryption, trust-management systems [105].  
  • Universal: Agent authentication, auditing (logging, trace analysis), access control (sandboxing, data segregation), and agent orchestration for fail-safe scheduling [34], [261].

---

### 3. Agent-Environment Communication
- **Representative Protocols**  
  • MCP (Model Context Protocol) [19]: Highly adopted protocol that unifies agent-to-tool communication with a registry of tool descriptors.  
  • API Bridge Agent [7]: Middleware that translates agent requests into structured API calls.  
  • Function Calling: Uses JSON schemas (e.g., OpenAI, LangChain) to serialize tool arguments [213], [154].  
  • agents.json [303]: Declares tool metadata so agents can dynamically load functionality.

- **Security Issues**  
  • Malicious Environments → Benign Agents  
    – Memory Attacks: Injection, poisoning, or extraction of agent memory [61].  
    – Knowledge Corruption: Poisoned retrieval corpora push agents to misleading info [365].  
    – Malicious Tools: Hidden instructions in tool code or descriptions [111], [229].  
  • Compromised Agents → Benign Environments  
    – Data Exfiltration: Abusing tool permissions to leak sensitive files or tokens [12].  
    – Service Disruption: Malicious or destructive commands that crash systems/DBs [273].  
    – Real-World Damage: Corrupted step-by-step reasoning leads to misconfigured devices or supply chains [190].

- **Defenses**  
  • Memory & Knowledge Hardening: Embedding-space anomaly detection, consensus filtering, gating suspicious retrievals [365].  
  • Tool Safety: Sandboxing, signature-based scanning (MCP-Scan [152]), guarded invocation.  
  • Secure Orchestration: Auditing chained tool calls, verifying intermediate outputs, limiting privileges [290], [304].

---

### 4. Experimental Illustrations (MCP & A2A)
- **MCP Attacks**  
  • Malicious Tool Execution: Attackers insert code to open a local shell on port 4444 [229].  
  • Retrieval Deception: Poisoned documents in a vector DB trigger malicious commands [45].  
  • Tool Poisoning: Tampered tool descriptions or metadata that instruct the agent to divulge private data [111].  
- **A2A Attacks**  
  • Agent Selection Manipulation: Attackers repeatedly emphasize “richest features” in their Agent_Card to override the ranking logic and hijack tasks [89].

---

### 5. Open Issues & Future Directions
- **Technical**  
  • Real-Time Communication Supervision & Decentralized Archiving: Challenge for P2P-based systems to monitor attacks promptly.  
  • Lightweight Defense Mechanisms: Balancing strong content filters with the inherent high computational cost.  
  • Accountability & Responsibility Assignment: Determining liability in multi-agent failures remains complex [218].  
  • Trade-off Between Efficiency & Accuracy: Long verbose contexts vs. concise structured formats require dynamic adaptation.

- **Legal & Regulatory**  
  • Responsibility Clarification: When multi-agent transactions fail, liability for damages is ambiguous.  
  • Intellectual Property Rights: There is no standardized framework for agent-level plagiarism or open-source constraints.  
  • Cross-Border Oversight: Lack of unified international laws to govern transnational agent-based systems.

**Overall Contribution**  
This survey clarifies the communication lifecycles of LLM-driven AI agents, categorizes known protocols (CS-based, P2P-based, hybrid), identifies new security shortcomings (e.g., agent spoofing, memory poisoning, cross-tool attacks), and proposes specific defense strategies. It provides a foundational reference for researchers and practitioners building secure, collaborative agent ecosystems.