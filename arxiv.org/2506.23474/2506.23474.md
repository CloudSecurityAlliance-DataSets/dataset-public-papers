# A Large-Scale Evolvable Dataset for Model Context Protocol **Ecosystem and Security Analysis**

Zhiwei Lin Bonan Ruan Jiahao Liu Weibo Zhao National University of Singapore

{zhiweil, r-bonan, jiahao99, weibo}@comp.nus.edu.sg

# **ABSTRACT**

The Model Context Protocol (MCP) has recently emerged as a standardized interface for connecting language models with external tools and data. As the ecosystem rapidly expands, the lack of a structured, comprehensive view of existing MCP artifacts presents challenges for research. To bridge this gap, we introduce MCPCOR-PUS, a large-scale dataset containing around 14K MCP servers and 300 MCP clients. Each artifact is annotated with 20+ normalized attributes capturing its identity, interface configuration, GitHub activity, and metadata. MCPCORPUS provides a reproducible snapshot of the real-world MCP ecosystem, enabling studies of adoption trends, ecosystem health, and implementation diversity. To keep pace with the rapid evolution of the MCP ecosystem, we provide utility tools for automated data synchronization, normalization, and inspection. Furthermore, to support efficient exploration and exploitation, we release a lightweight web-based search interface. MCPCORPUS is publicly available at: https://github.com/Snakinya/MCPCorpus.

### $\mathbf{1}$ **INTRODUCTION**

Given their strong capabilities in language understanding, reasoning, and decision-making, large language models (LLMs) have been increasingly integrated with diverse tools and services to collaboratively perform a wide range of tasks [8, 9].

However, due to the heterogeneity of tool interfaces and the lack of standardized integration protocols, swiftly integrating them remains challenging, which significantly hinders the development of LLM-based applications [7]. To address this challenge, Model Context Protocol (MCP) has been introduced as a lightweight, standardized interface that connects LLMs with diverse tools [1]. Specifically, MCP defines tools as callable endpoints with structured JSON schemas, allowing developers to expose services in a consistent and interoperable manner across different programming environments and platforms. Additionally, MCP employs a modular client-server architecture, where the MCP server registers tool capabilities and executes them upon request, while the MCP client discovers these capabilities and invokes the desired tools through a standardized protocol [10].

Although standardization has driven the rapid growth of MCP, fostering an active and expansive ecosystem, it has also exposed a range of issues, including inconsistent implementations, malicious server behaviors, and weak protocol compliance [2, 4]. This phenomenon has shifted the focus of research from merely exploring new applications of MCP to examining its reliability, security, and ecosystem dynamics [3, 11]. However, we identify several challenges in existing studies: (a) Limited-source investigation. Most works focus on MCP artifact information from a single source, ignoring the rich metadata available across different platforms such as code hosting sites (e.g., GitHub), community hubs (e.g., MCP. so [5]),

and package managers. (b) Unscalable analysis. These studies often rely on hand-picked examples, lacking the scalability needed for a comprehensive assessment of the MCP ecosystem's current state. The underlying reason is the absence of a large-scale, well-archived MCP dataset that consolidates MCP servers from diverse sources and unifies them for ease of use.

To bridge this gap and better support future research on the MCP ecosystem, we present MCPCorrus, a large-scale dataset accompanied by utility scripts for maintaining and continuously updating the dataset. MCPCoRPUS provides a comprehensive view of realworld MCP artifacts, currently including around 14K MCP servers and 300 MCP clients. For a clear overview and ease of analysis, each MCP artifact in MCPCorpus is annotated with over 20 metadata attributes, including type, tool list, programming language, license, author name, server configuration, and GitHub activity indicators. Take tool list as an example: it allows users to quickly understand the capabilities provided by an MCP server and how to interact with it, helping them efficiently determine whether the server is relevant for a given investigation. It is important to note that these attributes are extracted through static inspection of public repositories, without requiring runtime access or live service interaction.

With this dataset, we envision a range of potential applications, including (1) interoperability benchmarking of tool-augmented LLM agents, (2) security auditing of MCP implementations via linked source code analysis, and (3) schema conformance checking across diverse MCP artifacts. For example, researchers can locate implementations through metadata and inspect code to identify issues like missing authentication or unsafe endpoint exposure.

In summary, we make the following contributions:

- We curate a large-scale dataset named MCPCorrus, covering around 14K MCP servers and 300 clients from multiple sources. These artifacts span diverse domains and programming languages, and are annotated with 20+ normalized attributes to support ecosystem-level analysis.
- We develop a set of utility tools to support data synchronization, normalization, and inspection, as well as a public-facing web interface to explore the dataset.

### 2 **DATASET CONSTRUCTION**

To ensure that MCPCorPus can comprehensively profile MCPrelated artifacts and support various research and engineering tasks, we conduct a systematic investigation of the current MCP ecosystem and integrate information from multiple online sources. In particular, we focus on metadata-rich, actively maintained platforms that cover a wide range of MCP servers and clients.

In the subsequent sections, we first introduce the data sources selected for MCPCoRPUS and then elaborate on the data collection process, including our crawling strategy, metadata normalization, and attribute synthesis.

### 2.1 Data Sources

To construct a large-scale and high-quality dataset of MCP implementations, we combine two complementary sources: MCP.so, which hosts the largest and most information-rich collection of MCP tools, and GitHub, which provides additional implementation and maintenance metadata.

MCP.so is currently the most extensive registry dedicated to MCP servers and clients. As of 3 June 2025, MCP . so hosts over 14,000 MCP servers and 300 client implementations, and continues to update its database daily. Compared to other MCP hosting platforms, MCP. so offers the most comprehensive artifact-level information, including textual descriptions, domain tags, author identities, publication dates, and deployment statuses. To enable reliable analysis of the MCP ecosystem, we developed a unified metadata schema and systematically extracted and normalized over ten key attributes from MCP.so's unstructured content.

GitHub complements MCP. so by providing rich technical metadata for each associated repository. We extract statistics such as star count, forks, open issues, and contributors, as well as signals of activity and maintenance (e.g., last commit time and license type). We also detect technical traits like programming language composition, and the presence of Dockerfile and README files, which help enrich the static MCP registry entries with development context.

### $2.2\,$ **Data Collection**

The construction of MCPCorpus involves a five-stage pipeline to extract, enrich, normalize, and classify MCP artifacts from both centralized registries and decentralized code repositories. As shown in Figure 1, this process is designed to ensure the dataset is comprehensive, clean, and useful for both research and engineering tasks. The key stages are detailed as follows.

**Registry Crawling.** The collection process begins with crawling MCP. so. Our crawler systematically traverses its paginated listings and artifact detail pages to extract structured metadata, including artifact name, description, domain tags, category, tool schema, author information, deployment interface (e.g., REST APIs), creation/update timestamps, and GitHub URLs.

A total of around 13.9K MCP servers and 300 clients were extracted at the time of collection. For example, one of the MCP server projects, edgeone-pages-mcp, exposes a tool named deploy-html and is tagged under the cloud-platforms category, with a GitHub repository maintained by TencentEdgeOne.

GitHub Metadata Enrichment. For each MCP artifact with a valid GitHub link, we query the GitHub REST API to collect its repository-level attributes. These include popularity metrics (e.g., stars, forks), maintenance signals (e.g., last commit time, contributor count), license type, and the composition of programming languages (e.g., TypeScript, JavaScript). We also analyze the file structure to detect critical assets like README.md, Dockerfile, and other deployment-related files. For the aforementioned example, edgeone-pages-mcp, this phase confirms 125 stars, 16 forks, an MIT license, and recent activity (last commit in May 2025).

Zhiwei Lin, Bonan Ruan, Jiahao Liu, Weibo Zhao

![](_page_1_Figure_12.jpeg)

Figure 1: Approach Overview

Cleaning and Deduplication. To ensure data quality, we remove artifacts with invalid GitHub links, unreachable repositories, or insufficient metadata-defined as missing critical fields such as repository URLs. Duplicate detection is based on GitHub repository canonicalized URLs. If multiple entries point to the same repository (e.g., forks, mirrors, or renamed variants), we retain the version with the highest activity level (e.g., stars, recent commits) or the earliest creation timestamp as a proxy for originality. This process significantly reduces noise and ensures dataset consistency.

Metadata Normalization. Each artifact's metadata is parsed and normalized into a unified schema with 20+ attributes. These attributes include basic descriptors (e.g., category, interface type), technical metadata (e.g., programming language, license), and derived indicators (e.g., maintenance status, tool count). Fields originally encoded as JSON within the registry (e.g., tool definitions, custom metadata blocks) are parsed and flattened into structured representations, enabling efficient downstream querying, filtering, and analysis. As not all attributes are applicable to every artifact type (e.g., clients do not define tools), missing or inapplicable fields are filled with null.

Classification and Indexing. To facilitate structured exploration, each artifact is categorized along three core dimensions that are currently implemented: (i) artifact type (server or client), (ii) application category (e.g., cloud, AI, data), and (iii) programming language. These basic labels enable queries such as "Python-based AI servers" or "Go-written data clients." Additional dimensions such as interface type, officiality, and maintenance status are part of our design and will be integrated in future versions to support more fine-grained analysis.

Export and Tooling. The final dataset is stored in newlinedelimited JSON (JSONL) format. Each record contains merged registry and GitHub metadata along with classification tags. We also provide auxiliary tools for data synchronization, statistical analysis, and web-based exploration. These utilities enable reproducible updates and promote ease of integration into research pipelines.

### **DATASET DESCRIPTION** 3

#### $3.1$ **Basic Composition**

The MCPCoRPUS dataset consists of around 14K MCP artifacts, including 13,875 servers and 300 clients. Each artifact is represented as a JSON object with up to 26 structured attributes, combining metadata from MCP. so and enriched signals from GitHub repositories. These attributes describe the artifact's identity, deployment interface, functionality, language stack, license, and development A Large-Scale Evolvable Dataset for Model Context Protocol Ecosystem and Security Analysis

Conference' 17, July 2017, Washington, DC, USA

Table 1: Refined field schema of the MCPCORPUS dataset.

| Field              | Description                                |
|--------------------|--------------------------------------------|
| id                 | Unique identifier of the record            |
| name               | Short name of the MCP artifact             |
| title              | Display title of the project               |
| description        | Human-readable summary                     |
| author_name        | GitHub username or organization            |
| url                | Repository URL                             |
| category           | Domain category (e.g., AI, tools)          |
| tags               | Comma-separated topic labels               |
| type               | Whether the artifact is a server or client |
| tools              | MCP tools or functions exposed (JSON)      |
| sse url            | Callable endpoint if applicable            |
| server_command     | Execution command or entry point           |
| server_config      | Tool config and environment variables      |
| stargazers_count   | GitHub stars                               |
| forks_count        | GitHub forks                               |
| open_issues_count  | Number of open issues                      |
| contributors_count | Number of unique contributors              |
| last_commit        | Timestamp of the most recent commit        |
| full_name          | Full GitHub repo name (e.g., user/project) |
| language           | Primary implementation language            |
| languages          | Byte-level language breakdown              |
| license            | License type (e.g., MIT)                   |
| archived           | Whether the repository is archived         |
| has_docker         | Presence of a Dockerfile                   |
| has_readme         | Presence of README.md                      |
| has_requirements   | Presence of dependency declarations        |

Basic Info | Interface & Config | GitHub { Signals, Metadata }

activity. All entries conform to a unified schema, supporting consistent parsing and downstream processing.

## 3.2 Attribute Categorization

To support downstream analysis and improve the interpretability of the dataset, we group the refined fields into four functional categories based on their semantic roles and data sources. This categorization helps researchers and developers better understand the structure of each artifact and selectively utilize relevant attributes for specific tasks such as filtering, compatibility checking, and repository quality assessment. Table 1 provides an overview of all retained fields and their corresponding descriptions.

- Basic Information: Fields such as id, name, title, description, author\_name, url, category, tags, and type provide fundamental metadata that describes the identity, content, and domain classification of the MCP artifact.
- Interface and Configuration: Fields such as tools, sse\_url, server\_command, and server\_config capture how an MCP artifact exposes its functionality, including runtime interface details and tool execution configuration. These fields are critical for tool compatibility analysis and endpoint validation.
- · GitHub Signals: Fields such as stargazers\_count, forks\_count, open\_issues\_count, contributors\_count, and last\_commit represent quantitative signals extracted from GitHub that reflect

```
{ "id": 4493, "name": "playwright-mcp", "title": "
       ← Playwright Mcp"
   "url": "https://github.com/microsoft/playwright-
        \leftrightarrow mcp",
   "description": "Playwright MCP server", "
        → author_name": "microsoft"
   "tags": "mcp, playwright", "category": "browser-
   watomation",<br>"type": "server", "tools": "", "sse_url": null,<br>"server_command": "docker exec -i mcp-node bash
        → c \"npx @playwright/mcp@latest --headless<br>→ \"",
   "server_config": {"mcpServers": {"playwright": {"<br>
\hookrightarrow command": "npx",
   args": ["@playwright/mcp@latest","--headless<br>"args": ["@playwright/mcp@latest","--headless<br>"]}}},<br>"github": {"full_name": "microsoft/playwright-mcp<br>","forks_count": 727,<br>"stargazers_count": 11162, "open_issues_count":
        \rightarrow 22, "contributors_count": 24,
   "language": "TypeScript", "languages": {"
         \rightarrow TypeScript": 188386,
   "JavaScript": 13482, "Dockerfile": 2210}, "<br>\rightarrow license": "Apache License 2.0",
   " archived": false, "has_docker": true, "<br>"archived": false, "has_docker": true, "<br>"→ has_readme": true, "last_commit":
        \rightarrow "2025-06-03T18:10:47Z"}}
```

### Figure 2: Full MCP server entry covering all schema fields.

project popularity, development activity, and community engagement. They are useful for analyzing development characteristics and identifying active or well-supported artifacts.

• GitHub Metadata: Fields such as full name, language, languages, license, archived, has\_docker and has\_readme capture the technical structure, licensing, and documentation quality of each artifact. These attributes are valuable for security auditing, codebase profiling, and integration feasibility studies.

# 3.3 Data Sample

To illustrate the structure and metadata richness of individual entries in MCPCoRPUS, we present a representative MCP server named playwright-mcp, developed and maintained by Microsoft [6]. This artifact belongs to the browser-automation category and is implemented in TypeScript. It exposes a command-line interface for headless browser control via Playwright, with metadata drawn from both the MCP. so registry and the corresponding GitHub repository. A simplified version of the entry is shown in Figure 2. This sample contains all 26 structured fields defined in MCPCORPUS's schema, including both registry metadata (e.g., category, tags, server command) and GitHub-derived indicators (e.g., stars, forks, contributors). Even if some values are absent ( $e.g.,$   $\text{sse\_url}$ ), the corresponding keys are retained to preserve consistency across records.

# 3.4 Insights and Characteristics

To further understand the structure and dynamics of the MCP ecosystem, we analyze two critical characteristics from the MCP-CORPUS dataset: GitHub stargazer count and primary implementation language. These two features not only reflect project popularity and technical preference but also exhibit diverse distributions that support meaningful ecosystem-level insights.

![](_page_3_Figure_1.jpeg)

Figure 3: Distribution of GitHub stars for all MCP servers (left) and MCP clients (right).

![](_page_3_Figure_3.jpeg)

Figure 4: Primary programming language distribution for all MCP servers (left) and MCP clients (right).

Popularity Distribution. Figure 3 illustrates the distribution of GitHub stars across MCP artifacts. We observe a highly skewed long-tail pattern: the majority of projects (over 10,000) have fewer than 10 stars, while only a small fraction exceed 500 or 1,000 stars. This suggests that although the ecosystem is rapidly growing, most MCP projects remain in early stages of development or adoption. Notably, some highly starred projects surpass 5,000 stars, indicating early consolidation of a few popular tools.

Language Ecosystem. Figure 4 shows the distribution of primary programming languages among MCP artifacts. Specifically, Python, TypeScript, and JavaScript are the most commonly used languages, accounting for the majority of implementations. Languages such as Go, Rust, Java, and C# also appear but with lower frequency. Interestingly, the distribution is consistent even when filtered to the top-starred projects, suggesting that these languages are not only popular but also dominant among well-maintained, widely adopted MCP artifacts.

These observations confirm that MCPCorPUS captures both the breadth and structural concentration of the current MCP ecosystem, enabling downstream studies on language-specific adoption, sustainability, and integration practices.

### **APPLICATION SCENARIOS** $\overline{4}$

#### 4.1 **Ecosystem Analysis**

MCPCORPUS enables a systematic analysis of the MCP ecosystem by aggregating structured metadata across a diverse set of MCP server implementations. Through standardized fields such as language, license, last\_commit, and contributors\_count, researchers can investigate trends in programming language adoption, project vitality, and open-source collaboration patterns. Additionally, fields like created\_at, updated\_at, and stargazers\_count provide temporal insights into growth dynamics and community interest. This

Zhiwei Lin, Bonan Ruan, Jiahao Liu, Weibo Zhao

allows longitudinal tracking of the ecosystem's expansion and supports ecosystem health evaluation, including identifying undermaintained or overly centralized projects. Overall, MCPCORPUS functions as a longitudinal data source to support quantitative ecosystem modeling for LLM-integrated infrastructure.

### **Security and Code Quality Assessment** 4.2

Bevond ecosystem analysis, MCPCorpus facilitates research on the security posture and code quality of MCP servers and clients by exposing their runtime interface details and repository characteristics. Fields such as server\_command, server\_config, allow\_call, and tools reveal the external interface surface, which can be leveraged to evaluate attack exposure and command execution behavior. Metadata like has\_docker, has\_readme, and forks\_count reflects engineering completeness and adoption footprint, serving as auxiliary signals for maintainability and documentation hygiene. Combined with language and license information, MCPCoRPUS supports automated vulnerability analysis, dependency auditing, and cross-project policy enforcement. The dataset can serve as a benchmark corpus for empirical studies in secure-by-design MCP development and for training tools that assess AI-agent interoperability risks.

### 5 **CONCLUSION**

In this paper, we introduce MCPCoRPUS, a large-scale and evolvable dataset capturing the structure and dynamics of the MCP ecosystem. By integrating metadata from diverse sources, MCPCoRPUS offers a unified view of MCP artifacts, supporting analyses of interoperability, security, and ecosystem health. The dataset, along with utility tools, is publicly released to foster reproducible research and inform the development of robust, tool-augmented LLM systems.

### **REFERENCES**

- 2025. Model Context Protocol Specification. https://modelcontextprotocol.io/  $[1]$ specification/2025-03-26. Accessed 2025-06-14.
- $\lceil 2 \rceil$ 2025. WhatsApp MCP Exploited: Exfiltrating your message history via MCP. https://invariantlabs.ai/blog/whatsapp-mcp-exploited. Accessed 2025-06-23.
- [3] Junfeng Fang, Zijun Yao, Ruipeng Wang, Haokai Ma, Xiang Wang, and Tat-Seng Chua. 2025. We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems. arXiv preprint arXiv:2506.13666 (2025).
- [4] Xinyi Hou, Yanjie Zhao, Shenao Wang, and Haoyu Wang. 2025. Model context protocol (mcp): Landscape, security threats, and future research directions. arXiv preprint arXiv:2503.23278 (2025).
- mcp.so. 2025. MCP Servers mcp.so. https://mcp.so/.
- $56$ Microsoft. 2025. GitHub - microsoft/playwright-mcp: Playwright MCP server. https://github.com/microsoft/playwright-mcp.
- Nadia Nahar, Christian Kästner, Jenna Butler, Chris Parnin, Thomas Zimmermann, and Christian Bird. 2024. Beyond the Comfort Zone: Emerging Solutions to Overcome Challenges in Integrating LLMs into Software Products. arXiv preprint arXiv:2410.12071 (2024).
- Humza Naveed, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar,  $[8]$ Muhammad Usman, Naveed Akhtar, Nick Barnes, and Ajmal Mian. 2023. A comprehensive overview of large language models. arXiv preprint arXiv:2307.06435  $(2023)$ .
- [9] Zhuocheng Shen. 2024. Llm with tools: A survey. arXiv preprint arXiv:2409.18807  $(2024)$ .
- [10] Aditi Singh, Abul Ehtesham, Saket Kumar, and Tala Talaei Khoei. 2025. A survey of the model context protocol (mcp): Standardizing context to enhance large language models (llms). (2025).
- [11] Hao Song, Yiming Shen, Wenxuan Luo, Leixin Guo, Ting Chen, Jiashui Wang, Beibei Li, Xiaosong Zhang, and Jiachi Chen. 2025. Beyond the Protocol: Unveiling Attack Vectors in the Model Context Protocol Ecosystem. arXiv:2506.02040 [cs.CR] https://arxiv.org/abs/2506.02040